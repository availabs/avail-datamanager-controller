#!/usr/bin/env node

require("ts-node").register();
require("tsconfig-paths").register();

const { join } = require("path");

const yargs = require("yargs/yargs");
const { hideBin } = require("yargs/helpers");

const dama_events = require("data_manager/events").default;
const logger = require("data_manager/logger").default;
const dama_host_id = require("constants/damaHostId").default;

const { runInDamaContext } = require("data_manager/contexts");

const scheduled_etl_main = require("./scheduled-etl").default;

const worker_path = join(__dirname, "./scheduled-etl.worker.ts");

const { pg_env, state, is_expanded, override_max_partitions, logging_level } =
  yargs(hideBin(process.argv))
    .strict()
    .options({
      pg_env: {
        alias: "p",
        describe: "The PostgresSQL Database",
        demandOption: true,
      },
      is_expanded: {
        describe: "Use the RITIS expanded map",
        boolean: true,
        default: true,
      },
      override_max_partitions: {
        describe:
          "Override the batch max number of jobs. Defaults to 3 month/weeks max downloaded.",
        boolean: true,
        default: false,
      },
      logging_level: {
        alias: "l",
        describe: "The logging level",
        demandOption: false,
        default: "debug",
        choices: ["error", "warn", "info", "debug", "silly"],
      },
    }).argv;

logger.level = logging_level;

async function main() {
  const etl_context_id = await dama_events.spawnEtlContext(null, null, pg_env);

  const ctx = {
    meta: { pgEnv: pg_env, etl_context_id },
  };

  await runInDamaContext(ctx, async () => {
    const initial_event = {
      type: ":INITIAL",
      payload: {
        state,
        is_expanded,
        override_max_partitions,
      },
      meta: {
        note: `scheduled batch ETL from CLI`,
        // Because we are by-passing the TaskQueue, we need this to use ./runTask if later needed.
        __dama_task_manager__: {
          dama_host_id,
          worker_path,
        },
      },
    };

    await dama_events.dispatch(initial_event);

    logger.info(`==> etl_context_id: ${etl_context_id}`);

    await scheduled_etl_main(initial_event);

    console.log("after");
  });
}

main();
